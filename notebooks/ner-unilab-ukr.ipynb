{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12879112,"sourceType":"datasetVersion","datasetId":8148118}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:09.126550Z","iopub.execute_input":"2025-08-28T20:09:09.127213Z","iopub.status.idle":"2025-08-28T20:09:13.740942Z","shell.execute_reply.started":"2025-08-28T20:09:09.127183Z","shell.execute_reply":"2025-08-28T20:09:13.740207Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\nimport torch\nimport evaluate\n\ndef replace_tags(input_filepath, output_filepath):\n    \"\"\"\n    Читає файл, замінює теги 'B-PER' та 'I-PER' на 'B-PERS' та 'I-PERS'\n    відповідно, та зберігає результат у новий файл.\n    \"\"\"\n    try:\n        with open(input_filepath, 'r', encoding='utf-8') as infile:\n            content = infile.read()\n    except FileNotFoundError:\n        print(f\"Помилка: Файл не знайдено за шляхом '{input_filepath}'.\")\n        return False\n\n    updated_content = content.replace(\" B-PERS\", \" B-PER\").replace(\" I-PERS\", \" I-PER\")\n    \n    with open(output_filepath, 'w', encoding='utf-8') as outfile:\n        outfile.write(updated_content)\n\n    print(f\"Заміну тегів завершено. Оновлений файл збережено за шляхом: {output_filepath}\")\n    return True\n    \ndef process_iob_file(filepath):\n    \"\"\"\n    Читає файл IOB та повертає список словників, де кожен словник представляє речення.\n    Фільтрує дані, щоб залишити лише теги ORG та PERS.\n    \"\"\"\n    valid_tags = {'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'O'}\n    data = []\n    current_tokens = []\n    current_tags = []\n    \n    with open(filepath, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                if current_tokens:\n                    data.append({\"tokens\": current_tokens, \"ner_tags\": current_tags})\n                    current_tokens = []\n                    current_tags = []\n            else:\n                token, tag = line.split()\n                if tag not in valid_tags:\n                    tag = 'O'\n                current_tokens.append(token)\n                current_tags.append(tag)\n\n    if current_tokens:\n        data.append({\"tokens\": current_tokens, \"ner_tags\": current_tags})\n        \n    return data\n\ntrain_data = process_iob_file(\"/kaggle/input/data-ukr/train.iob\")\ntest_data = process_iob_file(\"/kaggle/input/data-ukr/test.iob\")\noriginal_train_path = \"/kaggle/input/data-ukr/train.iob\"\noriginal_test_path = \"/kaggle/input/data-ukr/test.iob\"\nupdated_train_path = \"train_pers.iob\"\nupdated_test_path = \"test_pers.iob\"\n\nif replace_tags(original_train_path, updated_train_path) and replace_tags(original_test_path, updated_test_path):\n    train_data = process_iob_file(updated_train_path)\n    test_data = process_iob_file(updated_test_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:13.742378Z","iopub.execute_input":"2025-08-28T20:09:13.742593Z","iopub.status.idle":"2025-08-28T20:09:41.978294Z","shell.execute_reply.started":"2025-08-28T20:09:13.742573Z","shell.execute_reply":"2025-08-28T20:09:41.977633Z"}},"outputs":[{"name":"stderr","text":"2025-08-28 20:09:28.582135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756411768.775926      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756411768.834786      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Заміну тегів завершено. Оновлений файл збережено за шляхом: train_pers.iob\nЗаміну тегів завершено. Оновлений файл збережено за шляхом: test_pers.iob\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_dataset = Dataset.from_list(train_data)\ntest_dataset = Dataset.from_list(test_data)\n\nprint(f\"Original dataset size: {len(train_data)} training sentences, {len(test_data)} test sentences.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:41.979003Z","iopub.execute_input":"2025-08-28T20:09:41.979575Z","iopub.status.idle":"2025-08-28T20:09:42.147044Z","shell.execute_reply.started":"2025-08-28T20:09:41.979552Z","shell.execute_reply":"2025-08-28T20:09:42.146447Z"}},"outputs":[{"name":"stdout","text":"Original dataset size: 11161 training sentences, 5087 test sentences.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"model_checkpoint = \"youscan/ukr-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n\nlabel_list = ['O', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER']\nlabel2id = {l: i for i, l in enumerate(label_list)}\nid2label = {i: l for i, l in enumerate(label_list)}\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint, \n    num_labels=len(label_list), \n    id2label=id2label, \n    label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:42.148796Z","iopub.execute_input":"2025-08-28T20:09:42.149009Z","iopub.status.idle":"2025-08-28T20:09:47.967245Z","shell.execute_reply.started":"2025-08-28T20:09:42.148991Z","shell.execute_reply":"2025-08-28T20:09:47.966660Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7599062e5b7142e79a6c6fe872d9d7f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb10db94b3a64b8db441f9bf296a40f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca4e64af983e4499b8f03ac98276a72a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb57b4486c20447ba19f46b61e55a8bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b29b62fb814294bc7e531815a1d0f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/507M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeec9b550649428b969f8a7254cfb7f0"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at youscan/ukr-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:47.968015Z","iopub.execute_input":"2025-08-28T20:09:47.968661Z","iopub.status.idle":"2025-08-28T20:09:47.973091Z","shell.execute_reply.started":"2025-08-28T20:09:47.968634Z","shell.execute_reply":"2025-08-28T20:09:47.972392Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['tokens', 'ner_tags'],\n    num_rows: 11161\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        truncation=True,\n        is_split_into_words=True,\n    )\n    labels_list = []\n    for i, labels in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label2id[labels[word_idx]])\n            else:\n                label_ids.append(label2id[labels[word_idx]])\n            previous_word_idx = word_idx\n        labels_list.append(label_ids)\n    \n    tokenized_inputs[\"labels\"] = labels_list\n    return tokenized_inputs\n\n\ntokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\ntokenized_test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:47.974163Z","iopub.execute_input":"2025-08-28T20:09:47.974427Z","iopub.status.idle":"2025-08-28T20:09:51.722868Z","shell.execute_reply.started":"2025-08-28T20:09:47.974404Z","shell.execute_reply":"2025-08-28T20:09:51.722117Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11161 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c883bab222b44589be66831691e0636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/507M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b55a6e999146aa99733e1f0d0e1d8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5087 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a052c81f1ba74ddd8f156253f2373441"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenized_train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:51.723632Z","iopub.execute_input":"2025-08-28T20:09:51.723850Z","iopub.status.idle":"2025-08-28T20:09:51.728677Z","shell.execute_reply.started":"2025-08-28T20:09:51.723833Z","shell.execute_reply":"2025-08-28T20:09:51.727925Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 11161\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(tokenized_train_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:51.729433Z","iopub.execute_input":"2025-08-28T20:09:51.729716Z","iopub.status.idle":"2025-08-28T20:09:51.852673Z","shell.execute_reply.started":"2025-08-28T20:09:51.729697Z","shell.execute_reply":"2025-08-28T20:09:51.851721Z"}},"outputs":[{"name":"stdout","text":"{'tokens': ['Дорогою', 'зупинялися', 'в', 'селах', ',', 'старцювали', '.', 'Устимко', 'приспівував', 'дідам', '.', 'Амфібрахій', 'шукав', 'підробіток', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O'], 'input_ids': [0, 42549, 500, 3326, 23574, 281, 15360, 1393, 2112, 792, 710, 1473, 407, 7203, 427, 390, 9608, 4087, 15664, 460, 1473, 12737, 724, 303, 741, 386, 34353, 426, 1770, 372, 1473, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, -100]}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:51.853470Z","iopub.execute_input":"2025-08-28T20:09:51.853698Z","iopub.status.idle":"2025-08-28T20:09:51.869339Z","shell.execute_reply.started":"2025-08-28T20:09:51.853674Z","shell.execute_reply":"2025-08-28T20:09:51.868774Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:09:51.871751Z","iopub.execute_input":"2025-08-28T20:09:51.871929Z","iopub.status.idle":"2025-08-28T20:10:04.344882Z","shell.execute_reply.started":"2025-08-28T20:09:51.871915Z","shell.execute_reply":"2025-08-28T20:10:04.343860Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=0c956780d6b346376ccc98d346e7e2138ae343d0b998128099bff6099a9b3f96\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nfrom seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:10:04.345852Z","iopub.execute_input":"2025-08-28T20:10:04.346105Z","iopub.status.idle":"2025-08-28T20:10:04.357684Z","shell.execute_reply.started":"2025-08-28T20:10:04.346061Z","shell.execute_reply":"2025-08-28T20:10:04.356916Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"metric = evaluate.load(\"seqeval\")\ndata_collator = DataCollatorForTokenClassification(tokenizer)\n\ndef compute_metrics(p):\n    preds_logits, labels = p\n    preds = np.argmax(preds_logits, axis=2)\n\n    id2label = model.config.id2label\n\n    true_labels = [\n        [id2label[l] for l in label_seq if l != -100]\n        for label_seq in labels\n    ]\n    true_preds = [\n        [id2label[p] for p, l in zip(pred_seq, label_seq) if l != -100]\n        for pred_seq, label_seq in zip(preds, labels)\n    ]\n\n    precision = precision_score(true_labels, true_preds)\n    recall = recall_score(true_labels, true_preds)\n    f1 = f1_score(true_labels, true_preds)\n    acc = accuracy_score(true_labels, true_preds)\n\n    return {\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n        \"accuracy\": acc,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:10:04.358540Z","iopub.execute_input":"2025-08-28T20:10:04.359246Z","iopub.status.idle":"2025-08-28T20:10:04.981015Z","shell.execute_reply.started":"2025-08-28T20:10:04.359221Z","shell.execute_reply":"2025-08-28T20:10:04.980297Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c646e30e9434353965723ee877a785c"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"model_output_dir = \"ukr_ner_model\"\ntraining_args = TrainingArguments(\n    output_dir=model_output_dir,\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    push_to_hub=False,\n    logging_dir='./logs',\n    logging_steps=100,\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:10:04.981869Z","iopub.execute_input":"2025-08-28T20:10:04.982154Z","iopub.status.idle":"2025-08-28T20:10:05.011011Z","shell.execute_reply.started":"2025-08-28T20:10:04.982131Z","shell.execute_reply":"2025-08-28T20:10:05.010451Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_test_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:10:05.011798Z","iopub.execute_input":"2025-08-28T20:10:05.012476Z","iopub.status.idle":"2025-08-28T20:10:05.328374Z","shell.execute_reply.started":"2025-08-28T20:10:05.012448Z","shell.execute_reply":"2025-08-28T20:10:05.327756Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3986238953.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(\"Starting training...\")\nres = trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:10:05.329251Z","iopub.execute_input":"2025-08-28T20:10:05.329490Z","iopub.status.idle":"2025-08-28T20:15:59.605070Z","shell.execute_reply.started":"2025-08-28T20:10:05.329470Z","shell.execute_reply":"2025-08-28T20:15:59.604332Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2094' max='2094' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2094/2094 05:52, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.039700</td>\n      <td>0.034813</td>\n      <td>0.884865</td>\n      <td>0.893426</td>\n      <td>0.889125</td>\n      <td>0.987793</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.016200</td>\n      <td>0.034414</td>\n      <td>0.888564</td>\n      <td>0.907655</td>\n      <td>0.898008</td>\n      <td>0.989126</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.007100</td>\n      <td>0.039309</td>\n      <td>0.892817</td>\n      <td>0.909078</td>\n      <td>0.900874</td>\n      <td>0.989032</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"output_dir = \"./ukr_fine_tuned_model\"\n\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\n\nprint(f\"Model and tokenizer saved to {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:15:59.605900Z","iopub.execute_input":"2025-08-28T20:15:59.606691Z","iopub.status.idle":"2025-08-28T20:16:00.676768Z","shell.execute_reply.started":"2025-08-28T20:15:59.606665Z","shell.execute_reply":"2025-08-28T20:16:00.676159Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved to ./ukr_fine_tuned_model\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"metrics = trainer.evaluate(tokenized_test_dataset)\nmetrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:16:00.677481Z","iopub.execute_input":"2025-08-28T20:16:00.677696Z","iopub.status.idle":"2025-08-28T20:16:14.806326Z","shell.execute_reply.started":"2025-08-28T20:16:00.677677Z","shell.execute_reply":"2025-08-28T20:16:14.805548Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [318/318 00:12]\n    </div>\n    "},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.03441426157951355,\n 'eval_precision': 0.8885638668338208,\n 'eval_recall': 0.907655093910074,\n 'eval_f1': 0.898008024213416,\n 'eval_accuracy': 0.9891257099802945,\n 'eval_runtime': 14.1173,\n 'eval_samples_per_second': 360.337,\n 'eval_steps_per_second': 22.525,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:16:14.806995Z","iopub.execute_input":"2025-08-28T20:16:14.807280Z","iopub.status.idle":"2025-08-28T20:16:14.812984Z","shell.execute_reply.started":"2025-08-28T20:16:14.807256Z","shell.execute_reply":"2025-08-28T20:16:14.811875Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"shutil.make_archive('ukr_ner_model', 'zip', './ukr_ner_model')\n\n# 2. Download it\nfrom IPython.display import FileLink\nFileLink(r'ukr_ner_model.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T20:16:14.814713Z","iopub.execute_input":"2025-08-28T20:16:14.816927Z","iopub.status.idle":"2025-08-28T20:19:40.736256Z","shell.execute_reply.started":"2025-08-28T20:16:14.816898Z","shell.execute_reply":"2025-08-28T20:19:40.735522Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/ukr_ner_model.zip","text/html":"<a href='ukr_ner_model.zip' target='_blank'>ukr_ner_model.zip</a><br>"},"metadata":{}}],"execution_count":19}]}